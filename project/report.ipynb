{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daTuBfs7jJVa",
    "colab_type": "text"
   },
   "source": [
    "# Final Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeJWQiUckzZy",
    "colab_type": "text"
   },
   "source": [
    "#### Sameer Mall\n",
    "#### CS 344\n",
    "#### 05/13/19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTxZniLMjxKF",
    "colab_type": "text"
   },
   "source": [
    "## Vision "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiWepqaFj1LQ",
    "colab_type": "text"
   },
   "source": [
    "Deep neural networks and deep learning have become really popular in the past few years. It has significantly improved the state of the art for many problems that machine learning and AI community has faced for many years. Deep learning is used in many different aspects of technology such as speech to text conversion, language translation (i.e. google translate), automated driving etc. Similarly, I also wanted to pursue a final project that would explore deep neural networks. \n",
    "I am a visual learner and I was very intrigued by the google image classification lab I did in class. For my final project I am going to build a CNN model using the Keras API and train it to recognize flower images (inspired by Google’s image classification course). For this image classification project, I will be using a flowers data set that I obtained from Kaggle.1 \n",
    "By working on this project, I hope to further enhance my understand of CNN models. The possibilities of using and implementing CNN’s are endless, so I feel like this project is going to be my entry project into the AI world. I have always been interested in how facial recognition works and why it is so secure. Apple on their newer phones and tablets has stopped using fingerprint ID and instead now only uses face ID. I hope that through building an application that can recognize flower images I will be able to somewhat see what goes on behind the scenes of popular face recognition systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSEajkltj4H5",
    "colab_type": "text"
   },
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubcHpjqKj63q",
    "colab_type": "text"
   },
   "source": [
    "The data set that I will be using contains 4242 images of flowers. The images are further divided up into five classes: chamomile, tulip, rose, sunflower, and dandelion. According to Chollet chapter 52 this is a small dataset. The labs I have done in class dealt with the MNIST dataset which is the most common dataset used for image classification and is easily accessible through TensorFlow and Keras, as they allow us to directly download from their API. MNIST datasets are generally also pre-sorted into training and testing set images. \n",
    "I will have to process and sort the data myself into training, testing, and validation sets and train the data from scratch. I will also need to rescale the images because otherwise the values are too high for our model to process. I will be using Matplot lib (lab 8) to plot the accuracy and loss over the training and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YL_G3UA1kDwi",
    "colab_type": "text"
   },
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIVJI4RMj9it",
    "colab_type": "text"
   },
   "source": [
    "The first thing I needed to do before I could start building my model was to split my flowers dataset, which contains 4242 images into training and testing sets. I did this by creating new directories for each of the five categories of flowers. Then I took the original dataset and split it ~75% training set and ~25% testing set.3 For user friendliness I had my program print the total number of images in the dataset, the total number of training images in each of the five flower categories, and lastly the total number of testing images in each of the five categories. \n",
    "\tInitially, I looked back at some of the MNIST convnet examples that I had done in class and used a chapter out of Chollet’s book.4 The convnet I am using has a stack of alternated layers of Conv2D (with relu activation, same padding) and then Maxpooling2D (with strides of (2,2)). I reshaped all the images to 150 x 150. I ended up implementing a 4-layer network because this prevents the model from having large feature maps when it gets to flattening the layers. The depth of the network started at 32 nodes and I did not increase the size of the network because I am working with a small dataset which means that overfitting and memorization is highly likely. Therefore, I kept the model fairly small. \n",
    "\tSince this a categorical classification problem I ended up with a Dense layer of 5 because we want a 5-way classification (one for each of the categories of flowers). Initially, I trained the model without a dropout layer, but my model is fairly strong, and the dataset is small, so it was memorizing way too fast. To somewhat solve this issue, I implemented a dropout layer of 0.3 (meaning it set 30% of the inputs to zero). I will talk about this more when I present my results in the section below. \n",
    "\tLastly to curb the problem of overfitting in a small dataset altogether I implemented data augmentation. This was much easier than I thought it would be. There are actually several built-in features in Keras that I used to augment the pictures. Some examples of the features are rotation_range, width_shift_range, horizontal_flip etc. I my code I have commented what each of these do. The main theory behind data augmentation is to feed new examples and noise in our dataset. Using data augmentation, the network convnet will never see the same image twice. Using this method, I finally got a model that was not overfitting the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TBBhIQrkHGp",
    "colab_type": "text"
   },
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NiTIWP6kSZr",
    "colab_type": "text"
   },
   "source": [
    "## Implications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZUugsBhkWNJ",
    "colab_type": "text"
   },
   "source": [
    "I think the main argument for this boils down to Alan Turing’s question, “Can machines think?” On the theoretical level this question is pretty clear in what’s its asking, but I came to have a greater understanding and appreciation of machine learning through working on this project. I don’t believe that machines can think in the same way that humans can. I say this firstly because machine learning does not make a machine think in the same way a human can. ML simply takes the input data and makes an initial assumption of some parameters and then makes adjustments to these parameters till an optimum is attained. It learns by seeing patterns in data and the more data you give your machine the better it’ll be able to generalize. You can teach a machine to recognize images of five flowers and it’ll be good at recognizing just those five types of flowers every time it sees them, but it’ll never be able to see another type of flower and classify it as a flower. \n",
    "\tFurthermore, AI and machine learning in recent years have had a massive impact on society as well. Kids today are growing up with AI voice assistants such as Siri, Alexa, Cortana etc. We have facial and fingerprint recognition on our phones and these technologies are becoming more and more efficient. I think there is a lot of stigma associated with Artificial Intelligence and Machine Learning in society because of Hollywood movies showing robots taking over the world and wiping out humanity and AI taking over a lot of jobs. AI robots have replaced a lot of jobs in the industry area such as packaging robots, transportation robots in amazon warehouses etc. Uber and Lyft are both currently working on autonomous driving technology, which will eventually eliminate the use of having Uber drivers.7 The struggle ML is facing today is having machines mimic human movements but slowly there are advancements being made in that sector as well. The impact AI is having on our society cannot be ignored and AI certainly will change the work and job industry a lot, but I believe that by having a competitive edge it is still possible to get ahead of the curve. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8lRbsMskJW0",
    "colab_type": "text"
   },
   "source": [
    "When I first implemented and got a CNN running, I was using a 4-layer network with the first layer having 32 nodes, the second layer having 64 nodes, and then I made the last 2 layers have 128 nodes each. I started with this approach because I had no idea what sort of network would work best because I had never done a small dataset image classification before. I was using relu and sigmoid as my activation functions with no padding and no strides (I added both of these features later) and tested using smaller batch sizes of 20 each. Since in class and the labs we had mainly done MNIST binary classification problems I initially used sigmoid as my activation function and labeled the “class_mode=binary” in the training generator. Since the convnet model was large and did binary classification it took really long to train and gave me a training accuracy of ~23.7% and validation accuracy of 26.15%. In addition, both the training and validation losses were high negative values. I then realized that I was looking at this problem the wrong way. This dataset has five categories of flowers which makes this a categorical classification problem. \n",
    "I left the entire model as it was but changed the activation function from sigmoid to softmax. Sigmoid works well for binary classification but for multi classification it can cause a neural network to get stuck at training time. The softmax function is a more generalized logistic activation function which works much better for multiclass classification.5 I also changed the label from binary_crossentropy to categorical_crossentropy. Just by making these two changes I saw significant improvements in my model. I re-trained the model by using a large batch size of 128, 50 steps per epoch, and did 30 epochs. \n",
    "This took about 3 hours to train but after that I had a model that was giving me very good results. In fact, they were a little too good to be true as the plots below indicte. The training accuracy kept increasing linearly over time until it eventually reached ~99.8%, while the validation accuracy stalled around ~55-60%. The validation loss reached its minimum after only about 4 epochs as you can see in the graph, whereas the training loss keeps decreasing until it reaches zero. These results are clear indicators of overfitting. Because I am using a small data set of only 4242 images, I realized that overfitting and memorization are going to be my biggest problems. \n",
    "In light of this, I trained my model again. I knew that I had a pretty powerful model that was working well. So, I mainly focused on reducing the amount of overfitting happening. I added a Dropout(0.2) layer which sets 20% of inputs to zero.6 I also reduced the number of nodes I had to just 32 in each of the 4 layers. Instead of running it for 30 epochs I used the early stoppage technique and ran it for only 15 epochs. After implementing these changes, I observed that the training time had already reduced significantly and gave slightly better results. The convnet model was still memorizing but it was taking longer to memorize. Validation loss was still slightly decreasing even at 15 epochs instead of reaching its minimum after 4 epochs previously. Accuracy however was not much better at all as you can see in the graphs. \n",
    "\tLastly, after I trained the model again using data augmentation. I did not make any changes to the convnet itself because it seemed to be working the way I expected it to. I only added features to augment the images in my training generator. One important thing to note here is that even though the network will never see the same image twice, the images are still heavily interconnected, since they are coming from a small dataset. There is no new data being produced, we are simply just mixing up the existing data. This did not completely get rid of overfitting, but it certainly did produce the best results as the graphs below indicate. Though I did not get enough time to train and retrain the model to improve it further, the results obtained from this model still yields 65-70% accuracy on the validation set. In addition, the training curves match the validation curves pretty closely for both the loss and accuracy. This is much better than the accuracy we were obtaining with a non-regularized model.  \n",
    "  *** All of the graphs that I refer to are found in the results folder ***\n",
    "  \n",
    "  I definitely believe that with more time and tweaking the parameters of the network will yield much higher accuracy and lower loss rates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rp5ic5nOkY51",
    "colab_type": "text"
   },
   "source": [
    "## Bibliography "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1m0GbvqfkBsj",
    "colab_type": "text"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd1jW3hNkgB6",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "1. https://www.kaggle.com/alxmamaev/flowers-recognition.\n",
    "2. https://github.com/fchollet/deep-learning-with-python-notebooks\n",
    "3. https://data-flair.training/blogs/train-test-set-in-python-ml/\n",
    "4. https://github.com/fchollet/deep-learning-with-python-notebooks\n",
    "5. https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6\n",
    "6. https://machinelearningmastery.com/how-to-reduce-overfitting-with-dropout-regularization-in-keras/\n",
    "7. https://www.forbes.com/sites/forbestechcouncil/2018/06/13/three-impacts-of-artificial-intelligence-on-society/#15cc1abe6ec0"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "report.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
