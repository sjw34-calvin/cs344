{
 "cells": [
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": true
   },
   "level": 1,
   "source": [
    "Exercise 1: Building a spam filter based on Paul Graham's A Plan for Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'like': 1, 'ham': 1, 'eggs': 1, 'i': 2, 'do': 2, 'green': 1, 'and': 1}\n{'spam': 2, 'like': 1, 'not': 1, 'i': 3, 'do': 1, 'am': 2, 'that': 1, 'spamiam': 1}\n{'spam': 0.99, 'like': 0.27272727272727276, 'not': 0, 'and': 0.01, 'i': 0.36, 'do': 0.15789473684210525, 'am': 0.99, 'that': 0, 'spamiam': 0}\nThe probability of this message being a spam message is: 0.999184422469161\nThe probability of this message being a spam message is: 0.00298396120850429\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A spam filter based on Paul Graham's A Plan for Spam.\n",
    "\n",
    "@author: Sameer Mall\n",
    "@professor: kvanderlinden\n",
    "@version March 06, 2019\n",
    "'''\n",
    "\n",
    "\n",
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "test1 = [\"spam\", \"I\", \"do\", \"am\", \"not\"]\n",
    "test2 = [\"green\", \"eggs\", \"ham\", \"and\"]\n",
    "\n",
    "\n",
    "good_corpus = {}\n",
    "bad_corpus = {}\n",
    "\n",
    "good_word = 0\n",
    "bad_word = 0\n",
    "\n",
    "\n",
    "def corpus_dictionary(corpus):\n",
    "    \"\"\"Returns a new corpus dictionary\"\"\"\n",
    "    new_dict = {}\n",
    "    for i in range(len(corpus)):\n",
    "        for j in range(len(corpus[i])):\n",
    "            word = corpus[i][j].lower()\n",
    "            if word in new_dict:\n",
    "                new_dict[word] = new_dict[word] + 1\n",
    "            else:\n",
    "                new_dict.update({word: 1})\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "\n",
    "def probability_dict(good_corpus, bad_corpus):\n",
    "    \"\"\"create a new dictionary where each token is mapped to a probability\"\"\"\n",
    "    for i in good_corpus:\n",
    "        b = 0\n",
    "        new_dict = {}\n",
    "        ngood = count_num_words(good_corpus)\n",
    "        nbad = count_num_words(bad_corpus)\n",
    "        g = 2 * good_corpus[i]\n",
    "        if i in bad_corpus:\n",
    "            b = bad_corpus[i]\n",
    "        if g + b > 1:\n",
    "            word_value = max(.01, min(.99, min(1.0, b/nbad) / (min(1.0, g/ngood) + min(1.0, b/nbad))))\n",
    "        new_dict[i] = word_value\n",
    "    \n",
    "    #go through the words in the bad corpus \n",
    "    for i in bad_corpus:\n",
    "        if i not in new_dict:\n",
    "            g = 0\n",
    "            word_value = 0\n",
    "            \n",
    "            if i in good_corpus:\n",
    "                g = 2 * good_corpus[i]\n",
    "            b = bad_corpus[i]\n",
    "            if g + b > 1:\n",
    "                word_value = max(.01, min(.99, min(1.0, b/nbad) / (min(1.0, g/ngood) + min(1.0, b/nbad))))\n",
    "            new_dict[i] = word_value\n",
    "    return new_dict\n",
    "\n",
    "\n",
    "def count_num_words(corpus):\n",
    "    \"\"\"Count the number of words in a given corpus\"\"\"\n",
    "    count = 0\n",
    "    for i in corpus:\n",
    "        count = count + corpus[i]\n",
    "    return count\n",
    "\n",
    "\n",
    "def calculate_spam_probability(prob_dict, message):\n",
    "    \"\"\"Calculates that the incoming message is spam or not spam\"\"\"\n",
    "    product = 1\n",
    "    complement_product = 1\n",
    "\n",
    "    for i in range(len(message)):\n",
    "        word = message[i]\n",
    "        if word in prob_dict:\n",
    "            if prob_dict[word] > 0:\n",
    "                product = product * prob_dict[word]\n",
    "                complement_product = complement_product * (1 - prob_dict[word])\n",
    "        else:\n",
    "            product = product * .4\n",
    "            complement_product = complement_product * 0.6\n",
    "    return product / (product + complement_product)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    good_corpus = corpus_dictionary(ham_corpus)\n",
    "    bad_corpus = corpus_dictionary(spam_corpus)\n",
    "    probability_dictionary = probability_dict(good_corpus, bad_corpus)\n",
    "    probability_spam = calculate_spam_probability(probability_dictionary, test1)\n",
    "\n",
    "    print(good_corpus)\n",
    "    print(bad_corpus)\n",
    "    print(probability_dictionary)\n",
    "    print(\"The probability of this message being a spam message is: \" + str(\n",
    "        calculate_spam_probability(probability_dictionary, test1)))\n",
    "    print(\"The probability of this message being a spam message is: \" + str(\n",
    "        calculate_spam_probability(probability_dictionary, test2)))"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Exercise 2: Bayesian Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False: 0.5, True: 0.5\nFalse: 0.9, True: 0.1\nFalse: 0.952, True: 0.0476\nFalse: 0.01, True: 0.99\nFalse: 0.639, True: 0.361\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This module implements the Bayesian network shown in the text, Figure 14.12.\n",
    "It's taken from the AIMA Python code.\n",
    "\n",
    "@author: Sameer Mall\n",
    "@professor: kvanderlinden\n",
    "@version Mar 06, 2019\n",
    "'''\n",
    "\n",
    "from probability import BayesNet, enumeration_ask, elimination_ask, gibbs_ask\n",
    "\n",
    "# Utility variables\n",
    "T, F = True, False\n",
    "\n",
    "# From AIMA code (probability.py) - Fig. 14.2 - burglary example\n",
    "cloudy = BayesNet([\n",
    "    ('Cloudy', '', 0.5),\n",
    "    ('Rain', 'Cloudy', {T: 0.80, F: 0.20}),\n",
    "    ('Sprinkler', 'Cloudy', {T: 0.10, F: 0.50}),\n",
    "    ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99, (T, F): 0.90, (F, T): 0.90, (F, F): 0.00})\n",
    "    ])\n",
    "\n",
    "# d. Compute probabilities for the following\n",
    "# i. P(Cloudy)\n",
    "print(enumeration_ask('Cloudy', dict(), cloudy).show_approx())\n",
    "# Output:\n",
    "#       False: 0.5, True: 0.5\n",
    "\n",
    "# ii. P(Sprinkler | cloudy)\n",
    "print(enumeration_ask('Sprinkler', dict(Cloudy=T), cloudy).show_approx())\n",
    "# Output:\n",
    "#       False: 0.9, True: 0.1\n",
    "\n",
    "# iii. P(Cloudy | the sprinkler is running and its not raining)\n",
    "print(enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=F), cloudy).show_approx())\n",
    "# Output:\n",
    "#       False: 0.952, True: 0.0476\n",
    "\n",
    "# iv. P(Wet Grass | its cloudy, the sprinkler is running and its raining)\n",
    "print(enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), cloudy).show_approx())\n",
    "# Output:\n",
    "#       False: 0.01, True: 0.99\n",
    "\n",
    "# v. P(Cloudy | the grass is not wet)\n",
    "print(enumeration_ask('Cloudy', dict(WetGrass=F), cloudy).show_approx())\n",
    "# Output:\n",
    "#       False: 0.639, True: 0.361\n",
    "\n",
    "# All of the hand worked solutions were done on paper which I put in your mailbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
